In this week's exercises we jumped into actually analyzing the historical data with text analysis tools. However, the work of historiography is not simply these analysis stages; it includes the earlier work to extract, organize and clean the data, all of which have an impact on the arguments we are making.

This work needs to documented and cited. As the “Digital History and Argument” white paper notes, "In assembling a digital collection, a historian makes an argument by structuring and describing the material in ways that highlight specific features and relationships." For our exercises with tools like Voyant and AntConc, we were given sample datasets to work on. However, in the real world, we would be assembling those datasets, and that includes making many decisions around: what data to extract, how to OCR it, the steps taken in OpenRefine to clean it etc; 

I found interesting the white paper's comparison of this digital history with reading regular prose, which also includes decisions made around the presentation of history. The paper says, "Creating visualizations requires choices about which data are to be used and how they are to be
arranged and represented—but then, those are common practices in the writing of historical prose as well." 

What needs to catch up seems to be practices around citing digital history - I suppose the requirement to make notes as we do our work is meant to fill this need. I noticed this line on the Topics Models course page: "A script like this might accompany a journal article, allowing the reviewers and the readers alike to experiment and see if the author’s conclusions are warranted." Using programming languages like R, or tools that work from the command line, may seem complicated at first but actually simplify that citation work afterwards, because all our steps can be followed.

This is already present in some other science-related disciplines. Papers are published with accompanying technical notes and the code is available for download.

But how do we include this in history? In those other discliplines - say something like computational biology - we can assume that other people in the field reading the paper have the knowledge to run the code. In history, that may not be the case. Does this reduce faith in the arguments being put forth?

Matthew Lincoln's Confabulation in the Humanities blog post shows the importance of this citation work in the digital history. He is highlighting a possible pitfall of having foregone explanations that can taint our analysis work. A researcher might make decisions throughout the data collection and analysis process to support a prior conclusion, but if the code or process is properly cited, perhaps the resulting plots can be verified and confirmed.

